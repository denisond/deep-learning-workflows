{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMvRt4zCENi0Z5GGatvhsOZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"UwKCeEZ4QDJt"},"source":["import torch\n","import torch.nn as nn\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zc9UqpBM7CDL"},"source":["# LOSS_FUNCTION = nn.BCEWithLogitsLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OQz2L0oTjebt"},"source":["class MoADataset:\n","    def __init__(self, features, targets):\n","        self.features = features\n","        self.targets = targets\n","    \n","    def __len__(self):\n","        return self.features.shape[0]\n","    \n","    def __getitem__(self, item):\n","        return {\n","            \"x\": torch.tensor(self.features[item, :], dtype=torch.float),\n","            \"y\": torch.tensor(self.targets[item, :], dtype=torch.float),\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Fovlb8Pk0ZX"},"source":["class Engine:\n","    def __init__(self, model, optimizer, device):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.device = device\n","    \n","\n","    @staticmethod\n","    def loss_fn(outputs, targets)):\n","        return nn.BCEWithLogitsLoss()(outputs, targets)\n","    \n","    def train(self, data_loader):\n","        self.model.train()\n","        final_loss = 0\n","        for data in data_loader:\n","            self.optimizer.zero_grad()\n","            inputs = data[\"x\"].to(self.device)\n","            targets = data[\"y\"].to(self.device)\n","            outputs = self.model(inputs)\n","            loss = self.loss_fn(outputs, targets)\n","            loss.backward()\n","            self.optimizer.step()\n","            final_loss += loss.item()\n","        return final_loss / len(data_loader)\n","\n","    def evaluate(self, data_loader):\n","        self.model.eval()\n","        final_loss = 0\n","        for data in data_loader:\n","            inputs = data[\"x\"].to(self.device)\n","            targets = data[\"y\"].to(self.device)\n","            outputs = self.model(inputs)\n","            loss = self.loss_fn(outputs, targets)\n","            final_loss += loss.item()\n","        return final_loss / len(data_loader)\n","\n","    # def add_dummies(data, column):\n","    #     ohe = pd.get_dummies(data[column])\n","    #     ohe_columns = [f\"{column}_{c}\" for c in ohe.columns]\n","    #     ohe.columns = ohe_columns\n","    #     data = data.drop(column, axis=1)\n","    #     data = data.join(ohe)\n","    #     return data\n","\n","    def process_data(data):\n","        ohe = pd.get_dummies(data[\"cp_time\"])\n","        ohe_columns = [f\"cp_time_{c}\" for c in ohe.columns]\n","        ohe.columns = ohe_columns\n","        data = data.drop(['cp_time'], axis=1)\n","        data = data.join(ohe)\n","\n","        ohe = pd.get_dummies(data[\"cp_dose\"])\n","        ohe_columns = [f\"cp_dose_{c}\" for c in ohe.columns]\n","        ohe.columns = ohe_columns\n","        data = data.drop(['cp_dose'], axis=1)\n","        data = data.join(ohe)\n","\n","        ohe = pd.get_dummies(data[\"cp_type\"])\n","        ohe_columns = [f\"cp_type_{c}\" for c in ohe.columns]\n","        ohe.columns = ohe_columns\n","        data = data.drop(['cp_type'], axis=1)\n","        data = data.join(ohe)\n","        return data\n","       \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w-EnqGGYjg6b"},"source":["class Model(nn.Module):\n","    def __init__(self, nfeatures, ntargets, nlayers, hidden_size, dropout):\n","        super().__init__()\n","        layers = []\n","        for _ in range(nlayers):\n","            if len(layers) == 0:\n","                layers.append(nn.Linear(nfeatures, hidden_size))\n","                layers.append(nn.BatchNorm1d(hidden_size))\n","                layers.append(nn.Dropout(dropout))\n","                layers.append(nn.ReLU())\n","            else:\n","                layers.append(nn.Linear(hidden_size, hidden_size))\n","                layers.append(nn.BatchNorm1d(hidden_size))\n","                layers.append(nn.Dropout(dropout))\n","                layers.append(nn.ReLU())\n","        layers.append(nn.Linear(hidden_size, ntargets))\n","        self.model = nn.Sequential(*layers)\n","        \n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n"],"execution_count":null,"outputs":[]}]}